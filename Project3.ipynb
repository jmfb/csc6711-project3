{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6129179e-ae40-43f1-a38f-17777e335cec",
   "metadata": {},
   "source": [
    "# CSC6711 Project 3 - Non-Personalized Recommendations\n",
    "\n",
    "* **Author**: Jacob Buysse\n",
    "\n",
    "This notebook is an analysis of the non-personalized predictions from the 4 datasets from Project 2 and how good they are at predicing the individual users actual ratings.  The files are located in the `datasets` subdirectory:\n",
    "* MovieLens - `movielens_25m.feather` (Movies)\n",
    "* Netflix Prize - `netflix_prize.feather` (Movies and TV Shows)\n",
    "* Yahoo! Music R2 - `yahoo_r2_songs.subsampled.feather` (Songs)\n",
    "* BoardGameGeek - `boardgamegeek.feather` (Board Games)\n",
    "\n",
    "We will be using the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5c0f8c7-2a0e-4e0c-9d64-4b91b60cb27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cd8bb-12e2-4f6f-9375-f024d158d28f",
   "metadata": {},
   "source": [
    "Let us configure matplotlib for readable labels, high resolution, and automatic layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64144893-b7c8-4b65-9ce6-f45b8c9542f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc('axes', labelsize=16)\n",
    "matplotlib.rc('figure', dpi=150, autolayout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e67e96-9312-4478-b079-0779be6a169d",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Let us load the databases using Pandas.  We know from Project 2 that the contents are structured identically:\n",
    "\n",
    "* `df1` - MovieLens\n",
    "* `df2` - Netflix\n",
    "* `df3` - Yahoo Music\n",
    "* `df4` - BoardGameGeek\n",
    "\n",
    "In each file, we have `item_id`, `user_id`, and `rating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d655ddf-64b5-434b-a1dc-72e17e2fec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_feather('./datasets/movielens_25m.feather')\n",
    "df2 = pd.read_feather('./datasets/netflix_prize.feather')\n",
    "df3 = pd.read_feather('./datasets/yahoo_r2_songs.subsampled.feather')\n",
    "df4 = pd.read_feather('./datasets/boardgamegeek.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e5865-0b5a-41e8-8931-7262673c22af",
   "metadata": {},
   "source": [
    "We need to tweak the data for BoardGameGeek.  It has user_id as a string and we will encode it to a numeric using `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f80d8abf-abd2-4b80-9022-4a8c86554d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id4_encoder = LabelEncoder()\n",
    "user_id4_encoder.fit(df4.user_id);\n",
    "df4['user_id'] = user_id4_encoder.transform(df4.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284eb44-2ac7-4bf6-8dbc-ee1b7123e55f",
   "metadata": {},
   "source": [
    "Next, let us split the datasets into 75/25 train/test subsets.  We will define a helper function `TrainTestSplit` to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48c68aa5-1a59-476c-b080-9ac97a2cc949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (18706943, 3) (75% total, 100% items, 75% users) Test (6183640, 3) (25% total, 99% items, 25% users)\n",
      "Train (38278492, 3) (75% total, 100% items, 75% users) Test (12752863, 3) (25% total, 100% items, 25% users)\n",
      "Train (5201846, 3) (75% total, 100% items, 75% users) Test (1735429, 3) (25% total, 100% items, 25% users)\n",
      "Train (14159851, 3) (75% total, 100% items, 75% users) Test (4782364, 3) (25% total, 100% items, 25% users)\n"
     ]
    }
   ],
   "source": [
    "def TrainTestSplit(df):\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.75, random_state=777)\n",
    "    train_index, test_index = next(gss.split(X=df, y=df.rating, groups=df.user_id))\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "    total_count = train_df.shape[0] + test_df.shape[0];\n",
    "    item_count = df.item_id.nunique()\n",
    "    user_count = df.user_id.nunique()\n",
    "    train_pct_total = train_df.shape[0] / total_count\n",
    "    test_pct_total = test_df.shape[0] / total_count\n",
    "    train_pct_item = train_df.item_id.nunique() / item_count\n",
    "    test_pct_item = test_df.item_id.nunique() / item_count\n",
    "    train_pct_user = train_df.user_id.nunique() / user_count\n",
    "    test_pct_user = test_df.user_id.nunique() / user_count\n",
    "    print(f\"Train {train_df.shape} ({train_pct_total:.0%} total, {train_pct_item:.0%} items, {train_pct_user:.0%} users) \" +\n",
    "          f\"Test {test_df.shape} ({test_pct_total:.0%} total, {test_pct_item:.0%} items, {test_pct_user:.0%} users)\")\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df1, test_df1 = TrainTestSplit(df1)\n",
    "train_df2, test_df2 = TrainTestSplit(df2)\n",
    "train_df3, test_df3 = TrainTestSplit(df3)\n",
    "train_df4, test_df4 = TrainTestSplit(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa681bd1-8229-43a8-bd29-f5b32f7a0e78",
   "metadata": {},
   "source": [
    "We can see we have a 75/25 split for total record count and additionally by users (the grouping provided by the `GroupShuffleSplit` helper).   We can also see that all items are accounted for in every training set and all but one testing set - with the remaining one still containing 99% of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c2259-8295-4d5c-abb4-1e3ffe1b6039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
